{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c51841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tensorflow_datasets\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a81754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='ted_hrlr_translate',\n",
      "    full_name='ted_hrlr_translate/pt_to_en/1.0.0',\n",
      "    description=\"\"\"\n",
      "    Data sets derived from TED talk transcripts for comparing similar language pairs\n",
      "    where one is high resource and the other is low resource.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    Translation dataset from pt to en in plain text.\n",
      "    \"\"\",\n",
      "    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n",
      "    data_path='/home/seal/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0',\n",
      "    download_size=124.94 MiB,\n",
      "    dataset_size=10.89 MiB,\n",
      "    features=Translation({\n",
      "        'en': Text(shape=(), dtype=tf.string),\n",
      "        'pt': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    supervised_keys=('pt', 'en'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=1803, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=51785, num_shards=1>,\n",
      "        'validation': <SplitInfo num_examples=1193, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n",
      "      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
      "      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
      "      booktitle = {HLT-NAACL},\n",
      "      year    = {2018},\n",
      "      }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "examples, info = tensorflow_datasets.load('ted_hrlr_translate/pt_to_en', with_info=True,as_supervised=True)\n",
    "train_data, val_data = examples['train'], examples['validation']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7986de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = tensorflow_datasets.deprecated.text.SubwordTextEncoder.build_from_corpus((en.numpy() for en,pt in train_data),target_vocab_size= 2**13)\n",
    "pt_tokenizer = tensorflow_datasets.deprecated.text.SubwordTextEncoder.build_from_corpus((pt.numpy() for en,pt in train_data),target_vocab_size= 2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97bbef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "buffer_size = 20000\n",
    "batch_size = 64\n",
    "max_length = 40\n",
    "\n",
    "def encode_to_subword(pt_sentence, en_sentence):#词汇表里有0 ~ vacab_size-1的序号，所以用vacab_size和vocab_size+1作为开始和结束的标识符\n",
    "    en_sequence =[en_tokenizer.vocab_size]\\\n",
    "    +en_tokenizer.encode(en_sentence.numpy())\\\n",
    "    +[en_tokenizer.vocab_size+1]\n",
    "    \n",
    "    pt_sequence =[pt_tokenizer.vocab_size]\\\n",
    "    +pt_tokenizer.encode(pt_sentence.numpy())\\\n",
    "    +[pt_tokenizer.vocab_size+1]\n",
    "    \n",
    "    return pt_sequence, en_sequence\n",
    "\n",
    "def filter_by_max_length(pt, en):    #判断长度是否<=40\n",
    "    return tf.logical_and(tf.size(pt) <=max_length, tf.size(en) <=max_length)\n",
    "    \n",
    "def tf_encode_to_subword(pt_sentence, en_sentence):    #进行pyfunction的封装\n",
    "    return tf.py_function(encode_to_subword,[pt_sentence, en_sentence], [tf.int64, tf.int64])\n",
    "    \n",
    "#生成训练与验证的数据集\n",
    "train_dataset = train_data.map(tf_encode_to_subword)\n",
    "train_dataset = train_dataset.filter(filter_by_max_length)     #舍弃长度大于40的数据\n",
    "train_dataset = train_dataset.shuffle(buffer_size).padded_batch(batch_size,padded_shapes= ([-1], [-1]))    #随机打乱数据， 将每64个样本补成相同长度\n",
    "\n",
    "val_dataset = val_data.map(tf_encode_to_subword)\n",
    "val_dataset = val_dataset.filter(filter_by_max_length)     #舍弃长度大于40的数据\n",
    "val_dataset = val_dataset.padded_batch(batch_size, padded_shapes= ([-1], [-1]))    #将每64个样本补成相同长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26c9cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40) (64, 39)\n",
      "(64, 40) (64, 38)\n",
      "(64, 40) (64, 40)\n",
      "(64, 40) (64, 39)\n",
      "(64, 40) (64, 40)\n"
     ]
    }
   ],
   "source": [
    "for en,pt in val_dataset.take(5):\n",
    "    print(en.shape,pt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe48cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#位置编码\n",
    "#pos.shape:[sample_length, 1]\n",
    "#i.shape = angles.shape = [1,d_model]\n",
    "#result.shape = [sample_length, d_model]\n",
    "\n",
    "def get_angles(pos, i, d_model):     #position:词语在句子中的位置， i:词语在embedding中的位置， d_model:embedding的大小\n",
    "    angle_rates = 1/np.power(10000, (i//2) * 2/np.float32(d_model))\n",
    "    return pos*angle_rates\n",
    "    \n",
    "def get_position_embedding(sentence_length, d_model):\n",
    "    angle_rads = get_angles(np.arange(sentence_length)[:,np.newaxis],         #生成一个shape为[sentence_length, 1]的矩阵\n",
    "                            np.arange(d_model)[np.newaxis, :],                 #生成一个shape为[1, d_model]的矩阵\n",
    "                            d_model)\n",
    "    sines = np.sin(angle_rads[:, 0::2])   #偶数位\n",
    "    cosines = np.cos(angle_rads[:, 1::2])   #奇数位\n",
    "    position_embedding = np.concatenate([sines, cosines], axis = 1)\n",
    "    position_embedding = position_embedding[np.newaxis, ...]   #在最前面扩展出一个新的维度\n",
    "    #shape:[1, sentence_length, d_model]\n",
    "    return tf.cast(position_embedding, dtype= tf.float32)   #数据类型转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de4d73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "position_embedding = get_position_embedding(40, 512)\n",
    "\n",
    "#绘制position_embedding\n",
    "def plot_position_embedding(position_embedding):\n",
    "    plt.pcolormesh(position_embedding[0])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('depth')\n",
    "    plt.ylabel('position')\n",
    "\n",
    "plot_position_embedding(position_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76870b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 1. 0.]]]], shape=(2, 1, 1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#padding mask\n",
    "def create_padding_mask(batch_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(batch_data, 0), tf.float32)       #将填充0部分的值设为1\n",
    "    return padding_mask[:, tf.newaxis, tf.newaxis, :]       #为便于后续计算，在中间添加两个维度\n",
    "\n",
    "#测试padding mask\n",
    "x = tf.constant([[1,4,0], [3, 0, 8]])\n",
    "print(create_padding_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e7fe1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 1., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look_ahead_mask\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)     #将右上角要去掉的部分的值设为1\n",
    "    return mask\n",
    "#测试look_ahead_mask\n",
    "create_look_ahead_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66fb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#缩放点积注意力机制\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "#     args:\n",
    "#         q: shape == [..., seq_len_q, depth]\n",
    "#         k: shape == [..., seq_len_k, depth]\n",
    "#         v: shape == [..., seq_len_v, depth_v]\n",
    "#         seq_length_k = seq_length_v （矩阵乘法）\n",
    "#         mask_shape = (..., seq_length_q, seq_length_k)\\\n",
    "#     returns:\n",
    "#         output: weighted_sum\n",
    "#         attention_weights: weights_of_attention (alpha)\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)        #矩阵乘法, k取转置\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)            #类型转换\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    #添加mask\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)       #将要去掉的部分的值加上-1e9,在softmax之后值趋近于0\n",
    "    #计算alpha\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis= -1)    #shape = (... , seq_len_q, seq_len_k)\n",
    "    output = tf.matmul(attention_weights, v)          #shape = (... , seq_len_q, depth)\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a45e509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()     #继承父类的构造方法\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        assert self.d_model %self.num_heads == 0\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        \n",
    "        self.WQ = keras.layers.Dense(self.d_model)     #三个全连接层用来计算qkv\n",
    "        \n",
    "        self.WK= keras.layers.Dense(self.d_model)\n",
    "        self.WV= keras.layers.Dense(self.d_model)\n",
    "        \n",
    "        self.dense = keras.layers.Dense(self.d_model)\n",
    "        \n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        #多头注意力机制的实现，对x进行reshape：（batch_size, seq_len, d_model）-> (batch_size, num_heads, seq_len, depth)\n",
    "        x = tf.reshape(x,(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0,2,1,3])     #这里维度转换是因为attention计算使用的是后两个维度\n",
    "    \n",
    "    def call(self, q, k, v, mask):\n",
    "        q = self.WQ(q)\n",
    "        k = self.WK(k)\n",
    "        v = self.WV(v)\n",
    "        \n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.split_heads(q, batch_size)     #shape: (batch_size, num_heads, seq_len, depth)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        outputs, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        #reshape： (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        outputs = tf.transpose(outputs, perm=[0,2,1,3])\n",
    "        #合并后两个维度\n",
    "        concat_attention = tf.reshape(outputs, (batch_size, -1, self.d_model))\n",
    "        \n",
    "        output = self.dense(concat_attention)    #output.shape = (batch_size, seq_len, d_model)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5beac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 512) (1, 8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "#测试multihead\n",
    "temp = MultiHeadAttention(d_model = 512, num_heads = 8)\n",
    "x = tf.random.uniform((1,60, 256))    #(batch_size, seq_len, dim)\n",
    "output, attention = temp(x,x,x,mask = None)\n",
    "print(output.shape, attention.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5044134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_network(d_model, dff):       #dff: dim of ffn\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(dff, activation = 'relu'), \n",
    "        keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f03cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    x -> self attention -> add & norm & dropout-> feed forward -> add & norm & dropout \n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):           #rate: 用于drop out\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        #x.shape: (batch_size, seq_len, dim) dim是embedding的维度或者上一层的维度\n",
    "        attention_output, _ = self.mha(x,x,x,mask)    #self attention的qkv都是自己\n",
    "        attention_output = self.dropout1(attention_output, training = training) #告诉dropout是训练还是测试\n",
    "        out1 = self.layer_norm1(x + attention_output)   #残差连接\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        out2 = self.layer_norm2(ffn_output + out1)\n",
    "        \n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b02b8243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "#测试Encoder Layer\n",
    "sample_encoder_layer = EncoderLayer(512,8, 2048)\n",
    "sample_input = tf.random.uniform((64,50,512))\n",
    "sample_output = sample_encoder_layer(sample_input, False, None)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "755652bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)    #self attention\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)    #encoder-decoder attention\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm3 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask):\n",
    "        #x.shape : (batch_size, target_seq_len, d_model)\n",
    "        #encoding_outputs.shape: (batch_size, input_seq_length, d_model)\n",
    "        \n",
    "        attention1, weights1 = self.mha1(x,x,x,decoder_mask)       #self attention\n",
    "        attention1 = self.dropout1(attention1, training = training)\n",
    "        out1 = self.layer_norm1(attention1 + x)\n",
    "        \n",
    "        attention2, weights2 = self.mha2(out1, encoding_outputs, encoding_outputs, encoder_decoder_padding_mask)  #encoder-decoder attention\n",
    "        attention2 = self.dropout2(attention2, training = training)\n",
    "        out2 = self.layer_norm2(attention2 + out1)\n",
    "        \n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out, training = training)\n",
    "        out3 = self.layer_norm3(ffn_out + out2)      #out3.shape : (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, weights1, weights2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3e801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 512) (64, 8, 60, 60) (64, 8, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "#测试decoder layer\n",
    "decoder_layer = DecoderLayer(512,8,2048)\n",
    "decoder_input = tf.random.uniform((64, 60, 512))\n",
    "output, weight1, weight2 = decoder_layer(decoder_input, sample_output, False, None, None)\n",
    "print(output.shape, weight1.shape, weight2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9b944f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, input_vocab_size, max_length, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size, self.d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, self.d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(self.num_layers)]\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        input_seq_length = tf.shape(x)[1]    #x.shape : (batch_size, seq_len)\n",
    "        tf.debugging.assert_less_equal(input_seq_length, self.max_length, \n",
    "                                       \"input_seq_len shoule be less or equal to self.max_length\")\n",
    "        \n",
    "        x = self.embedding(x)     #x.shape -> (batch_size, seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))    #对x进行缩放，增加x的影响\n",
    "        #position_embedding.shape = （1，max_length, d_model)\n",
    "        x += self.position_embedding[:, :input_seq_length, :]    #进行切片操作，使得x与embedding能够相加。x的batch size中的每一份都会加上一个position embedding\n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoder_layers[i](x, training, mask)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf2f7760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder_model = EncoderModel(2, 8500, max_length, 512, 8, 2048)\n",
    "sample_encoder_model_input = tf.random.uniform((64, 37))\n",
    "sample_encoder_model_output = sample_encoder_model(sample_encoder_model_input, False, None)\n",
    "print(sample_encoder_model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "743376cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, target_vocab_size, max_length, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(self.num_layers)]\n",
    "        \n",
    "    def call(self, x, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask):\n",
    "        #x.shape: (batch_size, output_seq_len)\n",
    "        output_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(output_seq_len, self.max_length,\"output_seq_len shoule be less or equal to self.max_length\")\n",
    "        \n",
    "        x = self.embedding(x)     #x.shape = (batch_size, output_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))      #类似Encoder model\n",
    "        x += self.position_embedding[:, :output_seq_len, :]\n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        attention_weights = {}\n",
    "        for i in range(self.num_layers):\n",
    "            x, attn1, attn2 = self.decoder_layers[i](x, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask)\n",
    "            attention_weights['decoder_layer{}_attn1'.format(i+1)] = attn1\n",
    "            attention_weights['decoder_layer{}_attn2'.format(i+1)] = attn2\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a5bb578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35, 512)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n"
     ]
    }
   ],
   "source": [
    "#测试Decoder Model\n",
    "sample_decoder_model = DecoderModel(2, 8000, max_length, 512, 8, 2048)\n",
    "sample_decoder_model_input = tf.random.uniform((64, 35))\n",
    "sample_decoder_model_output, sample_decoder_model_attention = sample_decoder_model(\n",
    "    sample_decoder_model_input,\n",
    "    sample_encoder_model_output,\n",
    "    training = False,\n",
    "    decoder_mask = None,\n",
    "    encoder_decoder_padding_mask = None\n",
    "                                                                                  )\n",
    "print(sample_decoder_model_output.shape)\n",
    "for key in sample_decoder_model_attention:\n",
    "    print(sample_decoder_model_attention[key].shape)    \n",
    "#结果说明：decoder model有两个decoder layer，每个layer分别包括decoder self attention（35，35）和encoder-decoder attention（35，37）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b23389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(self, num_layers, input_vocab_size, target_vocab_size, max_length, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder_model = EncoderModel(num_layers, input_vocab_size, max_length, d_model, num_heads, dff, rate)\n",
    "        self.decoder_model = DecoderModel(num_layers, target_vocab_size, max_length, d_model, num_heads, dff, rate)\n",
    "        self.final_layer = keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "    def call(self, inp, tar, training, encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask):\n",
    "        encoding_outputs = self.encoder_model(inp, training, encoder_padding_mask)\n",
    "        decoding_outputs, attention_weights = self.decoder_model(tar, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask)\n",
    "        predictions = self.final_layer(decoding_outputs)\n",
    "        return predictions, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6357cb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 31, 8000)\n",
      "decoder_layer1_attn1 (64, 8, 31, 31)\n",
      "decoder_layer1_attn2 (64, 8, 31, 26)\n",
      "decoder_layer2_attn1 (64, 8, 31, 31)\n",
      "decoder_layer2_attn2 (64, 8, 31, 26)\n"
     ]
    }
   ],
   "source": [
    "sample_transformer = Transformer(2, 8500, 8000, max_length, 512, 8, 2048)\n",
    "sample_transformer_input = tf.random.uniform((64, 26))\n",
    "sample_transformer_target = tf.random.uniform((64, 31))\n",
    "\n",
    "sample_transformer_predictions, sample_transformer_attn = sample_transformer(\n",
    "    sample_transformer_input, \n",
    "    sample_transformer_target,\n",
    "    False, None, None, None)\n",
    "\n",
    "print(sample_transformer_predictions.shape)\n",
    "for key in sample_transformer_attn:\n",
    "    print(key, sample_transformer_attn[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15dae2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.初始化模型\n",
    "# 2.定义loss, learning rate schedule, optimizer\n",
    "# 3.train step\n",
    "# 4.train process\n",
    "\n",
    "num_layers = 4\n",
    "d_model = 128      #模型的size\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = pt_tokenizer.vocab_size + 2\n",
    "target_vocab_size = en_tokenizer.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "\n",
    "transformer = Transformer(num_layers, input_vocab_size, target_vocab_size, \n",
    "                          max_length, d_model, num_heads, dff, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be2ab026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#论文中learning rate的调整方法\n",
    "#lrate = (d_model ** (-0.5)) * min(step_num ** (-0.5), step_number * warm_up_steps ** (-1.5))\n",
    "class CustomizedSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warm_up_steps = 4000):\n",
    "        super(CustomizedSchedule, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warm_up_steps = warm_up_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)     #step num ** -0.5\n",
    "        arg2 = step * (self.warm_up_steps ** (-1.5))\n",
    "        arg3 = tf.math.rsqrt(self.d_model)\n",
    "        \n",
    "        return arg3 * tf.math.minimum(arg2, arg1)\n",
    "    \n",
    "learning_rate = CustomizedSchedule(d_model)\n",
    "optimizer = keras.optimizers.Adam(learning_rate, beta_1= 0.9, beta_2 = 0.98, epsilon= 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6eaec67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe910be97f0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate_schedule = CustomizedSchedule(d_model)\n",
    "plt.plot(sample_learning_rate_schedule(tf.range(40000, dtype = tf.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e7dd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits= True, reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype= loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7be8aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    encoder_padding_mask = create_padding_mask(inp)\n",
    "    encoder_decoder_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    decoder_padding_mask = create_padding_mask(tar)\n",
    "    #decoder mask包括look ahead mask, padding mask\n",
    "    decoder_mask = tf.maximum(look_ahead_mask, decoder_padding_mask)\n",
    "    \n",
    "    return encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c587dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40)\n",
      "(64, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 1, 1, 40), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 39, 39), dtype=float32, numpy=\n",
       " array([[[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 1, 40), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_inp, tmp_tar = iter(train_dataset.take(1)).next()\n",
    "print(tmp_inp.shape)\n",
    "print(tmp_tar.shape)\n",
    "create_masks(tmp_inp, tmp_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc13949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1, Batch0, Loss5.0322, Accuracy0.0502\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function train_step at 0x7fe8749f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function train_step at 0x7fe8749f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function train_step at 0x7fe8749f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function train_step at 0x7fe8749f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x7fe8749f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x7fe8749f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7fe8749f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7fe8749f5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1, Batch100, Loss5.0245, Accuracy0.0538\n",
      "Epoch1, Batch200, Loss4.7259, Accuracy0.0533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-acfdf6ded9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             print('Epoch{}, Batch{}, Loss{:.4f}, Accuracy{:.4f}'.format(epoch+1, batch, \n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask = create_masks(inp, tar_inp)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, True, encoder_padding_mask, \n",
    "                                    decoder_mask, encoder_decoder_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n",
    "    \n",
    "epochs = 20      #遍历次数\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        if batch %100 == 0:\n",
    "            print('Epoch{}, Batch{}, Loss{:.4f}, Accuracy{:.4f}'.format(epoch+1, batch, \n",
    "                                                                        train_loss.result(), \n",
    "                                                                        train_accuracy.result()))\n",
    "    print('Epoch{}, Loss{:.4f}, Accuracy{:.4f}'.format(epoch+1, train_loss.result(), train_accuracy.result()))   \n",
    "    print('time take for 1 epoch: {}seconds\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec45b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e06cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb0076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
