{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c51841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tensorflow_datasets\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a81754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='ted_hrlr_translate',\n",
      "    full_name='ted_hrlr_translate/pt_to_en/1.0.0',\n",
      "    description=\"\"\"\n",
      "    Data sets derived from TED talk transcripts for comparing similar language pairs\n",
      "    where one is high resource and the other is low resource.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    Translation dataset from pt to en in plain text.\n",
      "    \"\"\",\n",
      "    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n",
      "    data_path='/home/seal/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0',\n",
      "    download_size=124.94 MiB,\n",
      "    dataset_size=10.89 MiB,\n",
      "    features=Translation({\n",
      "        'en': Text(shape=(), dtype=tf.string),\n",
      "        'pt': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    supervised_keys=('pt', 'en'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=1803, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=51785, num_shards=1>,\n",
      "        'validation': <SplitInfo num_examples=1193, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n",
      "      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
      "      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
      "      booktitle = {HLT-NAACL},\n",
      "      year    = {2018},\n",
      "      }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "examples, info = tensorflow_datasets.load('ted_hrlr_translate/pt_to_en', with_info=True,as_supervised=True)\n",
    "train_data, val_data = examples['train'], examples['validation']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7986de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = tensorflow_datasets.deprecated.text.SubwordTextEncoder.build_from_corpus((en.numpy() for en,pt in train_data),target_vocab_size= 2**13)\n",
    "pt_tokenizer = tensorflow_datasets.deprecated.text.SubwordTextEncoder.build_from_corpus((pt.numpy() for en,pt in train_data),target_vocab_size= 2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bbef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "buffer_size = 20000\n",
    "batch_size = 64\n",
    "max_length = 40\n",
    "\n",
    "def encode_to_subword(en_sentence, pt_sentence):#词汇表里有0 ~ vacab_size-1的序号，所以用vacab_size和vocab_size+1作为开始和结束的标识符\n",
    "    en_sequence =[en_tokenizer.vocab_size]\\\n",
    "    +en_tokenizer.encode(en_sentence.numpy())\\\n",
    "    +[en_tokenizer.vocab_size+1]\n",
    "    \n",
    "    pt_sequence =[pt_tokenizer.vocab_size]\\\n",
    "    +pt_tokenizer.encode(pt_sentence.numpy())\\\n",
    "    +[pt_tokenizer.vocab_size+1]\n",
    "    \n",
    "    return en_sequence, pt_sequence\n",
    "\n",
    "def filter_by_max_length(pt, en):    #判断长度是否<=40\n",
    "    return tf.logical_and(tf.size(pt) <=max_length, tf.size(en) <=max_length)\n",
    "    \n",
    "def tf_encode_to_subword(en_sentence, pt_sentence):    #进行pyfunction的封装\n",
    "    return tf.py_function(encode_to_subword,[en_sentence, pt_sentence], [tf.int64, tf.int64])\n",
    "    \n",
    "#生成训练与验证的数据集\n",
    "train_dataset = train_data.map(tf_encode_to_subword)\n",
    "train_dataset = train_dataset.filter(filter_by_max_length)     #舍弃长度大于40的数据\n",
    "train_dataset = train_dataset.shuffle(buffer_size).padded_batch(batch_size,padded_shapes= ([-1], [-1]))    #随机打乱数据， 将每64个样本补成相同长度\n",
    "\n",
    "val_dataset = val_data.map(tf_encode_to_subword)\n",
    "val_dataset = val_dataset.filter(filter_by_max_length)     #舍弃长度大于40的数据\n",
    "val_dataset = val_dataset.padded_batch(batch_size, padded_shapes= ([-1], [-1]))    #将每64个样本补成相同长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c9cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 38) (64, 40)\n",
      "(64, 39) (64, 35)\n",
      "(64, 39) (64, 39)\n",
      "(64, 39) (64, 39)\n",
      "(64, 39) (64, 36)\n"
     ]
    }
   ],
   "source": [
    "for en,pt in val_dataset.take(5):\n",
    "    print(en.shape,pt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe48cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#位置编码\n",
    "#pos.shape:[sample_length, 1]\n",
    "#i.shape = angles.shape = [1,d_model]\n",
    "#result.shape = [sample_length, d_model]\n",
    "\n",
    "def get_angles(pos, i, d_model):     #position:词语在句子中的位置， i:词语在embedding中的位置， d_model:embedding的大小\n",
    "    angle_rates = 1/np.power(10000, (i//2) * 2/np.float32(d_model))\n",
    "    return pos*angle_rates\n",
    "    \n",
    "def get_position_embedding(sentence_length, d_model):\n",
    "    angle_rads = get_angles(np.arange(sentence_length)[:,np.newaxis],         #生成一个shape为[sentence_length, 1]的矩阵\n",
    "                            np.arange(d_model)[np.newaxis, :],                 #生成一个shape为[1, d_model]的矩阵\n",
    "                            d_model)\n",
    "    sines = np.sin(angle_rads[:, 0::2])   #偶数位\n",
    "    cosines = np.cos(angle_rads[:, 1::2])   #奇数位\n",
    "    position_embedding = np.concatenate([sines, cosines], axis = 1)\n",
    "    position_embedding = position_embedding[np.newaxis, ...]   #在最前面扩展出一个新的维度\n",
    "    #shape:[1, sentence_length, d_model]\n",
    "    return tf.cast(position_embedding, dtype= tf.float32)   #数据类型转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de4d73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "position_embedding = get_position_embedding(40, 512)\n",
    "\n",
    "#绘制position_embedding\n",
    "def plot_position_embedding(position_embedding):\n",
    "    plt.pcolormesh(position_embedding[0])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('depth')\n",
    "    plt.ylabel('position')\n",
    "\n",
    "plot_position_embedding(position_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76870b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 1. 0.]]]], shape=(2, 1, 1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#padding mask\n",
    "def create_padding_mask(batch_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(batch_data, 0), tf.float32)       #将填充0部分的值设为1\n",
    "    return padding_mask[:, tf.newaxis, tf.newaxis, :]       #为便于后续计算，在中间添加两个维度\n",
    "\n",
    "#测试padding mask\n",
    "x = tf.constant([[1,4,0], [3, 0, 8]])\n",
    "print(create_padding_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e7fe1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 1., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look_ahead_mask\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)     #将右上角要去掉的部分的值设为1\n",
    "    return mask\n",
    "#测试look_ahead_mask\n",
    "create_look_ahead_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66fb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#缩放点积注意力机制\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "#     args:\n",
    "#         q: shape == [..., seq_len_q, depth]\n",
    "#         k: shape == [..., seq_len_k, depth]\n",
    "#         v: shape == [..., seq_len_v, depth_v]\n",
    "#         seq_length_k = seq_length_v （矩阵乘法）\n",
    "#         mask_shape = (..., seq_length_q, seq_length_k)\\\n",
    "#     returns:\n",
    "#         output: weighted_sum\n",
    "#         attention_weights: weights_of_attention (alpha)\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)        #矩阵乘法, k取转置\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)            #类型转换\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    #添加mask\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)       #将要去掉的部分的值加上-1e9,在softmax之后值趋近于0\n",
    "    #计算alpha\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis= -1)    #shape = (... , seq_len_q, seq_len_k)\n",
    "    output = tf.matmul(attention_weights, v)          #shape = (... , seq_len_q, depth)\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a45e509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()     #继承父类的构造方法\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        assert self.d_model %self.num_heads == 0\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        \n",
    "        self.WQ = keras.layers.Dense(self.d_model)     #三个全连接层用来计算qkv\n",
    "        \n",
    "        self.WK= keras.layers.Dense(self.d_model)\n",
    "        self.WV= keras.layers.Dense(self.d_model)\n",
    "        \n",
    "        self.dense = keras.layers.Dense(self.d_model)\n",
    "        \n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        #多头注意力机制的实现，对x进行reshape：（batch_size, seq_len, d_model）-> (batch_size, num_heads, seq_len, depth)\n",
    "        x = tf.reshape(x,(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0,2,1,3])     #这里维度转换是因为attention计算使用的是后两个维度\n",
    "    \n",
    "    def call(self, q, k, v, mask):\n",
    "        q = self.WQ(q)\n",
    "        k = self.WK(k)\n",
    "        v = self.WV(v)\n",
    "        \n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.split_heads(q, batch_size)     #shape: (batch_size, num_heads, seq_len, depth)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        outputs, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        #reshape： (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        outputs = tf.transpose(outputs, perm=[0,2,1,3])\n",
    "        #合并后两个维度\n",
    "        concat_attention = tf.reshape(outputs, (batch_size, -1, self.d_model))\n",
    "        \n",
    "        output = self.dense(concat_attention)    #output.shape = (batch_size, seq_len, d_model)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5beac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 512) (1, 8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "#测试multihead\n",
    "temp = MultiHeadAttention(d_model = 512, num_heads = 8)\n",
    "x = tf.random.uniform((1,60, 256))    #(batch_size, seq_len, dim)\n",
    "output, attention = temp(x,x,x,mask = None)\n",
    "print(output.shape, attention.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5044134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_network(d_model, dff):       #dff: dim of ffn\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(dff, activation = 'relu'), \n",
    "        keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f03cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    x -> self attention -> add & norm & dropout-> feed forward -> add & norm & dropout \n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):           #rate: 用于drop out\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        #x.shape: (batch_size, seq_len, dim) dim是embedding的维度或者上一层的维度\n",
    "        attention_output, _ = self.mha(x,x,x,mask)    #self attention的qkv都是自己\n",
    "        attention_output = self.dropout1(attention_output, training = training) #告诉dropout是训练还是测试\n",
    "        out1 = self.layer_norm1(x + attention_output)   #残差连接\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        out2 = self.layer_norm2(ffn_output + out1)\n",
    "        \n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b02b8243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "#测试Encoder Layer\n",
    "sample_encoder_layer = EncoderLayer(512,8, 2048)\n",
    "sample_input = tf.random.uniform((64,50,512))\n",
    "sample_output = sample_encoder_layer(sample_input, False, None)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "755652bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)    #self attention\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)    #encoder-decoder attention\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm3 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask):\n",
    "        #x.shape : (batch_size, target_seq_len, d_model)\n",
    "        #encoding_outputs.shape: (batch_size, input_seq_length, d_model)\n",
    "        \n",
    "        attention1, weights1 = self.mha1(x,x,x,decoder_mask)       #self attention\n",
    "        attention1 = self.dropout1(attention1, training = training)\n",
    "        out1 = self.layer_norm1(attention1 + x)\n",
    "        \n",
    "        attention2, weights2 = self.mha2(out1, encoding_outputs, encoding_outputs, encoder_decoder_padding_mask)  #encoder-decoder attention\n",
    "        attention2 = self.dropout2(attention2, training = training)\n",
    "        out2 = self.layer_norm2(attention2 + out1)\n",
    "        \n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out, training = training)\n",
    "        out3 = self.layer_norm3(ffn_out + out2)      #out3.shape : (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, weights1, weights2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3e801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 512) (64, 8, 60, 60) (64, 8, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "#测试decoder layer\n",
    "decoder_layer = DecoderLayer(512,8,2048)\n",
    "decoder_input = tf.random.uniform((64, 60, 512))\n",
    "output, weight1, weight2 = decoder_layer(decoder_input, sample_output, False, None, None)\n",
    "print(output.shape, weight1.shape, weight2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9b944f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, input_vocab_size, max_length, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size, self.d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, self.d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(self.num_layers)]\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        input_seq_length = tf.shape(x)[1]    #x.shape : (batch_size, seq_len)\n",
    "        tf.debugging.assert_less_equal(input_seq_length, self.max_length)\n",
    "        \n",
    "        x = self.embedding(x)     #x.shape -> (batch_size, seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))    #对x进行缩放，增加x的影响\n",
    "        #position_embedding.shape = （1，max_length, d_model)\n",
    "        x += self.position_embedding[:, :input_seq_length, :]    #进行切片操作，使得x与embedding能够相加。x的batch size中的每一份都会加上一个position embedding\n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoder_layers[i](x, training, mask)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf2f7760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder_model = EncoderModel(2, 8500, max_length, 512, 8, 2048)\n",
    "sample_encoder_model_input = tf.random.uniform((64, 37))\n",
    "sample_encoder_model_output = sample_encoder_model(sample_encoder_model_input, False, None)\n",
    "print(sample_encoder_model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "743376cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, target_vocab_size, max_length, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(self.num_layers)]\n",
    "        \n",
    "    def call(self, x, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask):\n",
    "        #x.shape: (batch_size, output_seq_len)\n",
    "        output_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(output_seq_len, self.max_length)\n",
    "        \n",
    "        x = self.embedding(x)     #x.shape = (batch_size, output_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))      #类似Encoder model\n",
    "        x += self.position_embedding[:, :output_seq_len, :]\n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        attention_weights = {}\n",
    "        for i in range(self.num_layers):\n",
    "            x, attn1, attn2 = self.decoder_layers[i](x, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask)\n",
    "            attention_weights['decoder_layer{}_attn1'.format(i+1)] = attn1\n",
    "            attention_weights['decoder_layer{}_attn2'.format(i+1)] = attn2\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a5bb578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35, 512)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n"
     ]
    }
   ],
   "source": [
    "#测试Decoder Model\n",
    "sample_decoder_model = DecoderModel(2, 8000, max_length, 512, 8, 2048)\n",
    "sample_decoder_model_input = tf.random.uniform((64, 35))\n",
    "sample_decoder_model_output, sample_decoder_model_attention = sample_decoder_model(\n",
    "    sample_decoder_model_input,\n",
    "    sample_encoder_model_output,\n",
    "    training = False,\n",
    "    decoder_mask = None,\n",
    "    encoder_decoder_padding_mask = None\n",
    "                                                                                  )\n",
    "print(sample_decoder_model_output.shape)\n",
    "for key in sample_decoder_model_attention:\n",
    "    print(sample_decoder_model_attention[key].shape)    \n",
    "#结果说明：decoder model有两个decoder layer，每个layer分别包括decoder self attention（35，35）和encoder-decoder attention（35，37）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b23389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(self, num_layers, input_vocab_size, target_vocab_size, max_length, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder_model = EncoderModel(num_layers, input_vocab_size, max_length, d_model, num_heads, dff, rate)\n",
    "        self.decoder_model = DecoderModel(num_layers, target_vocab_size, max_length, d_model, num_heads, dff, rate)\n",
    "        self.final_layer = keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "    def call(self, inp, tar, training, encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask):\n",
    "        encoding_outputs = self.encoder_model(inp, training, encoder_padding_mask)\n",
    "        decoding_outputs, attention_weights = self.decoder_model(tar, encoding_outputs, training, decoder_mask, encoder_decoder_padding_mask)\n",
    "        predictions = self.final_layer(decoding_outputs)\n",
    "        return predictions, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6357cb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 31, 8000)\n",
      "decoder_layer1_attn1 (64, 8, 31, 31)\n",
      "decoder_layer1_attn2 (64, 8, 31, 26)\n",
      "decoder_layer2_attn1 (64, 8, 31, 31)\n",
      "decoder_layer2_attn2 (64, 8, 31, 26)\n"
     ]
    }
   ],
   "source": [
    "sample_transformer = Transformer(2, 8500, 8000, max_length, 512, 8, 2048)\n",
    "sample_transformer_input = tf.random.uniform((64, 26))\n",
    "sample_transformer_target = tf.random.uniform((64, 31))\n",
    "\n",
    "sample_transformer_predictions, sample_transformer_attn = sample_transformer(\n",
    "    sample_transformer_input, \n",
    "    sample_transformer_target,\n",
    "    False, None, None, None)\n",
    "\n",
    "print(sample_transformer_predictions.shape)\n",
    "for key in sample_transformer_attn:\n",
    "    print(key, sample_transformer_attn[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15dae2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.初始化模型\n",
    "# 2.定义loss, learning rate schedule, optimizer\n",
    "# 3.train step\n",
    "# 4.train process\n",
    "\n",
    "num_layers = 4\n",
    "d_model = 128      #模型的size\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = pt_tokenizer.vocab_size + 2\n",
    "target_vocab_size = en_tokenizer.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "\n",
    "transformer = Transformer(num_layers, input_vocab_size, target_vocab_size, \n",
    "                          max_length, d_model, num_heads, dff, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be2ab026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#论文中learning rate的调整方法\n",
    "#lrate = (d_model ** (-0.5)) * min(step_num ** (-0.5), step_number * warm_up_steps ** (-1.5))\n",
    "class CustomizedSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warm_up_steps = 4000):\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warm_up_steps = warm_up_steps\n",
    "        \n",
    "    def call(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)     #step num ** -0.5\n",
    "        arg2 = step * (self.warm_up_steps ** (-1.5))\n",
    "        atg3 = tf.math.rsqrt(self.d_model)\n",
    "        \n",
    "        return arg3 * tf.math.minimum(arg2, arg1)\n",
    "    \n",
    "learning_rate = CustomizedSchedule(d_model)\n",
    "optimizer = keras.optimizers.Adam(learning_rate, beta_1= 0.9, beta_2 = 0.98, epsilon= 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e7dd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits= True, reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype= loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7be8aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    encoder_padding_mask = create_padding_mask(inp)\n",
    "    encoder_decoder_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    decoder_padding_mask = create_padding_mask(tar)\n",
    "    #decoder mask包括look ahead mask, padding mask\n",
    "    decoder_mask = tf.maximum(look_ahead_mask, decoder_padding_mask)\n",
    "    \n",
    "    return encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc13949e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    <ipython-input-28-acfdf6ded9d1>:16 train_step  *\n        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:499 apply_gradients  **\n        apply_state = self._prepare(var_list)\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:752 _prepare\n        self._prepare_local(var_device, var_dtype, apply_state)\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/adam.py:164 _prepare_local\n        super(Adam, self)._prepare_local(var_device, var_dtype, apply_state)\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:758 _prepare_local\n        lr_t = array_ops.identity(self._decayed_lr(var_dtype))\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:810 _decayed_lr\n        lr_t = math_ops.cast(lr_t(local_step), var_dtype)\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:44 __call__\n        raise NotImplementedError(\"Learning rate schedule must override __call__\")\n\n    NotImplementedError: Learning rate schedule must override __call__\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-acfdf6ded9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             print('Epoch{}, Batch{}, Loss{:.4f}, Accuracy{:.4f}'.format(epoch+1, batch, \n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    <ipython-input-28-acfdf6ded9d1>:16 train_step  *\n        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:499 apply_gradients  **\n        apply_state = self._prepare(var_list)\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:752 _prepare\n        self._prepare_local(var_device, var_dtype, apply_state)\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/adam.py:164 _prepare_local\n        super(Adam, self)._prepare_local(var_device, var_dtype, apply_state)\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:758 _prepare_local\n        lr_t = array_ops.identity(self._decayed_lr(var_dtype))\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:810 _decayed_lr\n        lr_t = math_ops.cast(lr_t(local_step), var_dtype)\n    /home/seal/anaconda3/envs/ML2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:44 __call__\n        raise NotImplementedError(\"Learning rate schedule must override __call__\")\n\n    NotImplementedError: Learning rate schedule must override __call__\n"
     ]
    }
   ],
   "source": [
    "train_loss = keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask = create_masks(inp, tar_inp)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, True, encoder_padding_mask, \n",
    "                                    decoder_mask, encoder_decoder_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n",
    "    \n",
    "epochs = 20      #遍历次数\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        if batch %100 == 0:\n",
    "            print('Epoch{}, Batch{}, Loss{:.4f}, Accuracy{:.4f}'.format(epoch+1, batch, \n",
    "                                                                        train_loss.result(), \n",
    "                                                                        train_accuracy.result()))\n",
    "    print('Epoch{}, Loss{:.4f}, Accuracy{:.4f}'.format(epoch+1, train_loss.result(), train_accuracy.result()))   \n",
    "    print('time take for 1 epoch: {}seconds\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec45b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e06cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb0076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
